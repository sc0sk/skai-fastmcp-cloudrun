# Data Model: Search and Fetch MCP Tools

**Feature**: 004-search-fetch-mcp-tools | **Date**: 2025-10-23 | **Status**: Implementation Complete

## Overview

This document describes the database schemas and Pydantic models used by the search and fetch MCP tools. The implementation uses a dual-table architecture: `speeches` for full text metadata storage and `speech_chunks` (LangChain's `langchain_pg_embedding` table) for vector embeddings.

---

## Database Schemas

### speeches Table

Stores complete speech text and all metadata fields. Optimized for fast retrieval by `speech_id`.

```sql
CREATE TABLE IF NOT EXISTS speeches (
    speech_id TEXT PRIMARY KEY,              -- UUID v4 (auto-generated)
    title TEXT NOT NULL,                     -- Speech title/subject
    speaker TEXT NOT NULL,                   -- MP/Senator name
    party TEXT,                              -- Political party
    chamber TEXT,                            -- "House of Representatives" or "Senate"
    state TEXT,                              -- Australian state/territory (NSW, VIC, QLD, etc.)
    date DATE NOT NULL,                      -- Speech date (ISO 8601)
    hansard_reference TEXT,                  -- Official Hansard citation
    full_text TEXT NOT NULL,                 -- Complete speech transcript
    word_count INTEGER,                      -- Word count (computed)
    electorate TEXT,                         -- Electorate (House members only, NULL for Senators)
    topic_tags TEXT[],                       -- Array of topic tags
    source_url TEXT,                         -- Source URL (optional)
    content_hash TEXT UNIQUE,                -- SHA-256 hash for deduplication
    ingestion_timestamp TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- Indexes for common queries
CREATE INDEX IF NOT EXISTS speeches_speaker_idx ON speeches(speaker);
CREATE INDEX IF NOT EXISTS speeches_date_idx ON speeches(date);
CREATE INDEX IF NOT EXISTS speeches_party_idx ON speeches(party);
CREATE INDEX IF NOT EXISTS speeches_chamber_idx ON speeches(chamber);
```

**Key Fields**:
- `speech_id`: Primary key, UUID v4 format (e.g., "550e8400-e29b-41d4-a716-446655440000")
- `full_text`: Complete speech transcript (10+ words minimum)
- `chamber`: Must be exactly "House of Representatives" or "Senate"
- `electorate`: Required for House members, NULL for Senators
- `state`: Australian state/territory codes (NSW, VIC, QLD, WA, SA, TAS, ACT, NT)
- `content_hash`: SHA-256 hash of full_text for detecting duplicates
- `topic_tags`: PostgreSQL array of lowercase tags (e.g., {"climate change", "energy policy"})

**Constraints**:
- `speech_id` is primary key (unique, not null)
- `content_hash` has unique constraint (prevents duplicate speeches)
- `title`, `speaker`, `full_text`, `date` are required (NOT NULL)
- Chamber validation enforced by application logic (Pydantic)
- Electorate validation: NULL for Senate, required for House of Representatives

---

### speech_chunks Table (LangChain Schema)

Stores speech chunks with vector embeddings for semantic search. Uses LangChain's default schema (`langchain_pg_embedding`).

```sql
CREATE TABLE IF NOT EXISTS speech_chunks (
    chunk_id TEXT PRIMARY KEY,               -- UUID v4 (auto-generated by LangChain)
    speech_id TEXT NOT NULL REFERENCES speeches(speech_id) ON DELETE CASCADE,
    chunk_index INTEGER NOT NULL,            -- Position in speech (0-based)
    chunk_text TEXT NOT NULL,                -- Chunk text content
    chunk_size INTEGER NOT NULL,             -- Character count
    embedding vector(768),                   -- 768-dimensional embedding (text-embedding-005)
    speaker TEXT NOT NULL,                   -- Denormalized from parent speech
    party TEXT,                              -- Denormalized from parent speech
    chamber TEXT,                            -- Denormalized from parent speech
    state TEXT,                              -- Denormalized from parent speech
    date DATE NOT NULL,                      -- Denormalized from parent speech
    hansard_reference TEXT,                  -- Denormalized from parent speech
    title TEXT,                              -- Denormalized from parent speech
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(speech_id, chunk_index)           -- Prevent duplicate chunks for same speech
);

-- HNSW index for fast vector similarity search
CREATE INDEX IF NOT EXISTS speech_chunks_embedding_idx
ON speech_chunks
USING hnsw (embedding vector_cosine_ops)
WITH (m = 24, ef_construction = 100);

-- Indexes for common queries
CREATE INDEX IF NOT EXISTS speech_chunks_speech_id_idx ON speech_chunks(speech_id);
CREATE INDEX IF NOT EXISTS speech_chunks_speaker_idx ON speech_chunks(speaker);
CREATE INDEX IF NOT EXISTS speech_chunks_date_idx ON speech_chunks(date);
```

**Note**: LangChain uses the table name specified in configuration. This implementation uses `speech_chunks` instead of the LangChain default `langchain_pg_embedding`, but the schema follows LangChain's standard column structure.

**Key Fields**:
- `chunk_id`: Primary key, UUID v4 (generated by LangChain)
- `speech_id`: Foreign key to parent speech (cascade delete)
- `chunk_index`: 0-based position in speech (e.g., 0, 1, 2, ...)
- `chunk_text`: Chunk content (typically 500-1500 characters)
- `embedding`: 768-dimensional vector from Vertex AI text-embedding-005
- Denormalized fields: speaker, party, chamber, state, date, hansard_reference, title

**Constraints**:
- `(speech_id, chunk_index)` unique constraint ensures no duplicate chunks
- Foreign key with `ON DELETE CASCADE` removes chunks when speech deleted
- `embedding` must be 768 dimensions (enforced by vector type)

**HNSW Index Parameters**:
- `m = 24`: Number of bi-directional links per node (higher = better accuracy, more memory)
- `ef_construction = 100`: Size of dynamic candidate list during index construction (higher = better accuracy, slower builds)
- `vector_cosine_ops`: Use cosine similarity for distance calculation

---

## Pydantic Models

### SpeechMetadata

Core speech model with all 29 metadata fields. Used for ingestion and fetch tool responses.

```python
from datetime import date as date_type
from typing import List, Optional
from pydantic import BaseModel, Field, computed_field, field_validator

class SpeechMetadata(BaseModel):
    """Pydantic model for speech metadata validation during ingestion."""

    # Core identification
    speech_id: Optional[str] = Field(
        None, description="UUID v4 (auto-generated if not provided)"
    )
    title: str = Field(..., min_length=1, max_length=500, description="Speech title/subject")

    # Content
    full_text: str = Field(..., min_length=10, description="Complete speech transcript")

    # Speaker information
    speaker: str = Field(..., min_length=1, max_length=200, description="MP/Senator name")
    party: str = Field(..., min_length=1, max_length=100, description="Political party")
    chamber: str = Field(..., description="House of Representatives or Senate")
    electorate: Optional[str] = Field(
        None, max_length=100, description="Electorate (House members only)"
    )
    state: Optional[str] = Field(None, description="Australian state/territory")

    # Parliamentary context
    date: date_type = Field(..., description="Speech date (ISO 8601)")
    hansard_reference: str = Field(
        ..., min_length=1, max_length=500, description="Official Hansard citation"
    )
    topic_tags: List[str] = Field(default_factory=list, description="Topic tags")

    # Source
    source_url: Optional[str] = Field(None, max_length=1000, description="Source URL")

    # Computed fields
    @computed_field
    @property
    def word_count(self) -> int:
        """Calculate word count from full_text."""
        return len(self.full_text.split())

    @computed_field
    @property
    def content_hash(self) -> str:
        """Generate SHA-256 hash for deduplication."""
        return hashlib.sha256(self.full_text.encode("utf-8")).hexdigest()

    # Validators
    @field_validator("chamber")
    @classmethod
    def validate_chamber(cls, v: str) -> str:
        """Validate chamber is valid Australian chamber."""
        valid_chambers = {"House of Representatives", "Senate"}
        if v not in valid_chambers:
            raise ValueError(f"chamber must be one of: {valid_chambers}")
        return v

    @field_validator("state")
    @classmethod
    def validate_state(cls, v: Optional[str]) -> Optional[str]:
        """Validate state is valid Australian state/territory."""
        if v is None:
            return v
        valid_states = {"NSW", "VIC", "QLD", "WA", "SA", "TAS", "ACT", "NT"}
        if v not in valid_states:
            raise ValueError(f"state must be one of: {valid_states}")
        return v

    @field_validator("topic_tags")
    @classmethod
    def validate_topic_tags(cls, v: List[str]) -> List[str]:
        """Normalize topic tags (lowercase, strip whitespace)."""
        return [tag.strip().lower() for tag in v if tag.strip()]

    def model_post_init(self, __context) -> None:
        """Validate electorate based on chamber."""
        if self.chamber == "Senate" and self.electorate is not None:
            raise ValueError("Senators cannot have electorate (must be NULL)")
        if self.chamber == "House of Representatives" and self.electorate is None:
            raise ValueError("House members must have electorate")
```

**File**: `/home/user/skai-fastmcp-cloudrun/src/models/speech.py`

**Field Details**:

| Field | Type | Required | Constraints | Description |
|-------|------|----------|-------------|-------------|
| speech_id | str | No | UUID v4 format | Auto-generated if not provided |
| title | str | Yes | 1-500 chars | Speech title/subject |
| full_text | str | Yes | 10+ chars | Complete speech transcript |
| speaker | str | Yes | 1-200 chars | MP/Senator name |
| party | str | Yes | 1-100 chars | Political party |
| chamber | str | Yes | Enum | "House of Representatives" or "Senate" |
| electorate | str | No | 1-100 chars | Required for House, NULL for Senate |
| state | str | No | Enum | NSW, VIC, QLD, WA, SA, TAS, ACT, NT |
| date | date | Yes | ISO 8601 | Speech date (YYYY-MM-DD) |
| hansard_reference | str | Yes | 1-500 chars | Official Hansard citation |
| topic_tags | List[str] | No | Array | Lowercase tags |
| source_url | str | No | 1-1000 chars | Source URL |
| word_count | int | Computed | Read-only | Auto-calculated from full_text |
| content_hash | str | Computed | Read-only | SHA-256 hash of full_text |

**Validation Rules**:
1. Chamber must be exactly "House of Representatives" or "Senate"
2. State must be one of 8 Australian states/territories
3. Topic tags normalized to lowercase, whitespace stripped
4. Senators cannot have electorate (must be NULL)
5. House members must have electorate
6. Word count auto-calculated by splitting full_text on whitespace
7. Content hash auto-calculated using SHA-256

---

### SpeechDetail

Extended speech model with ingestion timestamp. Inherits all fields from SpeechMetadata.

```python
class SpeechDetail(SpeechMetadata):
    """Extended speech model with full details (returned by fetch tool)."""

    ingestion_timestamp: Optional[str] = Field(
        None, description="When speech was ingested (ISO 8601)"
    )
```

**File**: `/home/user/skai-fastmcp-cloudrun/src/models/speech.py`

**Additional Fields**:
- `ingestion_timestamp`: ISO 8601 timestamp (e.g., "2024-03-24T10:30:00Z")

**Usage**: Returned by `fetch_hansard_speech` tool to provide complete speech details including ingestion metadata.

---

### SpeechChunkMetadata

Metadata for individual speech chunks. Used internally by LangChain vector store.

```python
class SpeechChunkMetadata(BaseModel):
    """Metadata for individual speech chunks (used internally by LangChain)."""

    # Chunk identification
    chunk_id: Optional[str] = Field(None, description="UUID v4 (auto-generated)")
    speech_id: str = Field(..., description="Parent speech UUID")
    chunk_index: int = Field(..., ge=0, description="Position in speech (0-based)")
    chunk_size: int = Field(..., gt=0, description="Character count")

    # Denormalized metadata for filtering
    speaker: str = Field(..., description="Speaker name")
    party: str = Field(..., description="Political party")
    chamber: str = Field(..., description="Chamber")
    date: date_type = Field(..., description="Speech date")
    topic_tags: List[str] = Field(default_factory=list, description="Topic tags")

    # Additional metadata
    hansard_reference: str = Field(..., description="Official citation")
    title: str = Field(..., description="Speech title")
```

**File**: `/home/user/skai-fastmcp-cloudrun/src/models/speech.py`

**Field Details**:

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| chunk_id | str | No | UUID v4 (auto-generated by LangChain) |
| speech_id | str | Yes | Parent speech UUID |
| chunk_index | int | Yes | Position in speech (0, 1, 2, ...) |
| chunk_size | int | Yes | Character count (must be > 0) |
| speaker | str | Yes | Speaker name (denormalized) |
| party | str | Yes | Political party (denormalized) |
| chamber | str | Yes | Chamber (denormalized) |
| date | date | Yes | Speech date (denormalized) |
| topic_tags | List[str] | No | Topic tags (denormalized) |
| hansard_reference | str | Yes | Official citation (denormalized) |
| title | str | Yes | Speech title (denormalized) |

**Denormalization Rationale**: Metadata fields duplicated from parent speech to enable fast filtering during vector search without joining to `speeches` table.

---

## Enum Types

### PartyEnum

Australian political parties represented in the dataset.

```python
from typing import Literal

PartyEnum = Literal[
    "Liberal",      # Liberal Party of Australia
    "Labor",        # Australian Labor Party (note: "Labor" not "Labour")
    "Greens",       # Australian Greens
    "National",     # National Party of Australia
    "Independent"   # Independent MPs
]
```

**File**: `/home/user/skai-fastmcp-cloudrun/src/models/enums.py`

**Usage**: MCP tool parameter type for `party` filter in `search_hansard_speeches`.

**Valid Values**:
- `"Liberal"` - Liberal Party of Australia
- `"Labor"` - Australian Labor Party (note spelling)
- `"Greens"` - Australian Greens
- `"National"` - National Party of Australia
- `"Independent"` - Independent MPs

---

### ChamberEnum

Australian Parliament chambers.

```python
ChamberEnum = Literal[
    "House of Representatives",  # Lower house
    "Senate"                     # Upper house
]
```

**File**: `/home/user/skai-fastmcp-cloudrun/src/models/enums.py`

**Usage**: MCP tool parameter type for `chamber` filter in `search_hansard_speeches`.

**Valid Values**:
- `"House of Representatives"` - Lower house (151 members, electorate-based)
- `"Senate"` - Upper house (76 members, state-based)

---

## Relationships

### speeches ↔ speech_chunks

- **Type**: One-to-Many
- **Foreign Key**: `speech_chunks.speech_id` → `speeches.speech_id`
- **Cascade**: `ON DELETE CASCADE` (deleting speech removes all chunks)
- **Uniqueness**: `(speech_id, chunk_index)` unique constraint prevents duplicate chunks

**Diagram**:

```
┌─────────────────────────────────┐
│          speeches               │
│─────────────────────────────────│
│ speech_id (PK)                  │
│ title                           │
│ full_text                       │
│ speaker                         │
│ party                           │
│ chamber                         │
│ date                            │
│ ... (29 total fields)           │
└─────────────────────────────────┘
          │
          │ 1:N (ON DELETE CASCADE)
          │
          ▼
┌─────────────────────────────────┐
│        speech_chunks            │
│─────────────────────────────────│
│ chunk_id (PK)                   │
│ speech_id (FK) ───────────────┐ │
│ chunk_index                   │ │
│ chunk_text                    │ │
│ embedding vector(768)         │ │
│ speaker (denormalized)        │ │
│ party (denormalized)          │ │
│ chamber (denormalized)        │ │
│ date (denormalized)           │ │
│ ... (denormalized metadata)   │ │
└─────────────────────────────────┘
```

**Key Points**:
1. Each speech has 1-50 chunks (typical: 3-15)
2. Chunks store denormalized metadata for fast filtering
3. Deleting speech automatically deletes all chunks
4. Chunk order preserved via `chunk_index` (0-based)

---

## Data Flow

### Ingestion Flow

1. **Input**: Markdown file with YAML frontmatter (29 metadata fields) + speech text
2. **Parse**: Extract metadata and full_text
3. **Validate**: Create `SpeechMetadata` instance (Pydantic validation)
4. **Store Metadata**: Insert into `speeches` table
5. **Chunk**: Split full_text into chunks (500-1500 chars with 200-char overlap)
6. **Embed**: Generate 768-dim vectors via Vertex AI Embeddings
7. **Store Chunks**: Insert into `speech_chunks` table with embeddings

### Search Flow

1. **Input**: Query string + optional filters (party, chamber, date range)
2. **Embed Query**: Generate 768-dim vector via Vertex AI Embeddings
3. **Vector Search**: Find top K similar chunks using HNSW index
4. **Filter**: Apply party/chamber/date filters to results
5. **Enrich**: Retrieve full speech metadata from `speeches` table
6. **Return**: List of speeches with excerpts, relevance scores, metadata

### Fetch Flow

1. **Input**: speech_id (UUID)
2. **Query**: `SELECT * FROM speeches WHERE speech_id = ?`
3. **Validate**: Raise ValueError if not found
4. **Return**: Complete speech with all 29 metadata fields + computed fields

---

## Example Data

### Example Speech Record (speeches table)

```json
{
  "speech_id": "550e8400-e29b-41d4-a716-446655440000",
  "title": "Second Reading: Climate Change Bill 2024",
  "full_text": "Mr Speaker, I rise to speak on the Climate Change Bill 2024...",
  "speaker": "Anthony Albanese",
  "party": "Labor",
  "chamber": "House of Representatives",
  "electorate": "Grayndler",
  "state": "NSW",
  "date": "2024-03-23",
  "hansard_reference": "House Hansard, 23 March 2024, p.145",
  "topic_tags": ["climate change", "environment", "energy policy"],
  "source_url": "https://www.aph.gov.au/Parliamentary_Business/Hansard",
  "word_count": 1847,
  "content_hash": "a3f8d9c2e1b4f7e6d5c8b9a1e2f3d4c5b6a7e8f9d0c1b2a3e4f5d6c7b8a9",
  "ingestion_timestamp": "2024-03-24T10:30:00Z",
  "created_at": "2024-03-24T10:30:00Z",
  "updated_at": "2024-03-24T10:30:00Z"
}
```

### Example Chunk Record (speech_chunks table)

```json
{
  "chunk_id": "123e4567-e89b-12d3-a456-426614174000",
  "speech_id": "550e8400-e29b-41d4-a716-446655440000",
  "chunk_index": 0,
  "chunk_text": "Mr Speaker, I rise to speak on the Climate Change Bill 2024. This legislation represents a critical step forward in Australia's commitment to reducing emissions...",
  "chunk_size": 782,
  "embedding": [0.023, -0.156, 0.089, ...],  // 768 dimensions
  "speaker": "Anthony Albanese",
  "party": "Labor",
  "chamber": "House of Representatives",
  "state": "NSW",
  "date": "2024-03-23",
  "hansard_reference": "House Hansard, 23 March 2024, p.145",
  "title": "Second Reading: Climate Change Bill 2024",
  "created_at": "2024-03-24T10:30:00Z"
}
```

---

## Storage Statistics

**Current Dataset** (Simon Kennedy speeches):
- Speeches: 64
- Chunks: 628
- Avg chunks per speech: 9.8
- Total embeddings: 628 × 768 dimensions = 482,304 floats
- Estimated storage: ~30 MB (embeddings) + ~5 MB (text) = ~35 MB

**Projected at Scale** (10,000 speeches):
- Speeches: 10,000
- Chunks: ~98,000 (assuming same avg)
- Total embeddings: 98,000 × 768 = 75,264,000 floats
- Estimated storage: ~4.7 GB (embeddings) + ~800 MB (text) = ~5.5 GB

**HNSW Index Size**: ~20-30% overhead on embedding storage (~1.4 GB for 10k speeches)

---

## References

- Source code: `/home/user/skai-fastmcp-cloudrun/src/models/speech.py`
- Database schema: `/home/user/skai-fastmcp-cloudrun/init_hansard_db_v2.sql`
- Enum definitions: `/home/user/skai-fastmcp-cloudrun/src/models/enums.py`
- LangChain schema docs: https://python.langchain.com/docs/integrations/vectorstores/google_cloud_sql_pg
