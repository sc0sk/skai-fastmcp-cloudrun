# Implementation Plan: Australian Hansard RAG MVP

**Branch**: `001-hansard-rag-implementation` | **Date**: 2025-10-21 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/001-hansard-rag-implementation/spec.md`

**Note**: This template is filled in by the `/speckit.plan` command. See `.specify/templates/commands/plan.md` for the execution workflow.

## Summary

Build a FastMCP server for semantic search over Australian Hansard parliamentary speeches using Google ADK-aligned architecture (LangChain + Vertex AI + Cloud SQL pgvector). Implements paragraph-aware chunking, 768-dimensional embeddings, and hybrid search with metadata filtering. MVP supports local development with STDIO transport and provides foundation for Cloud Run deployment.

## Technical Context

**Language/Version**: Python 3.11+ (Cloud Run compatible)
**Primary Dependencies**: FastMCP 2.12.2, LangChain (langchain-google-vertexai, langchain-google-cloud-sql-pg), Pydantic v2
**Storage**: Cloud SQL PostgreSQL 15 + pgvector v0.8.0 (768-dim vectors, HNSW indexing)
**Testing**: pytest with >80% coverage target, integration tests with MCP Inspector
**Target Platform**: Google Cloud Run (containerized), local development via STDIO
**Project Type**: Single MCP server project
**Performance Goals**: <500ms search latency (p95), 1 speech/sec ingestion throughput
**Constraints**: Vertex AI quota (768-dim embeddings), Cloud SQL connection limits, paragraph-aware chunking (800 chars)
**Scale/Scope**: MVP with 64 speeches (Simon Kennedy dataset), expandable to 1000+ speeches in production

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

| Principle | Status | Notes |
|-----------|--------|-------|
| I. FastMCP Server-First | âœ… PASS | Tools implemented with @mcp.tool decorator, full annotations (readOnlyHint, idempotentHint, openWorldHint) |
| II. GitHub OAuth | âš ï¸ DEFERRED | OAuth deferred to v2 per spec, MVP uses local STDIO transport |
| III. Secrets Management | âœ… PASS | .env with .gitignore, DATABASE_PASSWORD in env vars, no secrets in git |
| IV. Test-Driven Development | âš ï¸ PARTIAL | Integration tests exist, unit test coverage <80% target |
| V. Structured Result Handling | âœ… PASS | Tools return Dict[str, Any] with structured data, error handling via exceptions |
| VI. Cloud Run Standards | âœ… PASS | Dockerfile ready, environment-based config, health checks planned |
| VII. Progress Transparency | âŒ NOT IMPLEMENTED | Ingestion script doesn't use ctx.report_progress (CLI script, not MCP tool) |
| VIII. Python & Pydantic | âœ… PASS | Python 3.11+, Pydantic v2 models, uv package manager, type hints throughout |
| IX. ChatGPT Integration | âš ï¸ PLANNED | HTTP transport not yet configured, STDIO only in MVP |
| X. MCP JSON Config | âš ï¸ PLANNED | fastmcp.json not yet generated |
| XI. Separation of Concerns | âœ… PASS | Ingestion via CLI scripts/, MCP tools read-only (search, fetch, stats) |
| XII. Tool Implementation | âœ… PASS | Full docstrings, type annotations, async functions, annotations present |

**Post-Implementation Re-check**: Constitution alignment is strong for MVP. Deferred items (OAuth, ChatGPT, progress reporting) are intentional scope reductions documented in spec.md.

## Project Structure

### Documentation (this feature)

```
specs/[###-feature]/
â”œâ”€â”€ plan.md              # This file (/speckit.plan command output)
â”œâ”€â”€ research.md          # Phase 0 output (/speckit.plan command)
â”œâ”€â”€ data-model.md        # Phase 1 output (/speckit.plan command)
â”œâ”€â”€ quickstart.md        # Phase 1 output (/speckit.plan command)
â”œâ”€â”€ contracts/           # Phase 1 output (/speckit.plan command)
â””â”€â”€ tasks.md             # Phase 2 output (/speckit.tasks command - NOT created by /speckit.plan)
```

### Source Code (repository root)

```
skai-fastmcp-cloudrun/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/              # Pydantic models (Speech, SearchResult)
â”‚   â”œâ”€â”€ storage/             # LangChain vector store + metadata store
â”‚   â”‚   â”œâ”€â”€ embeddings.py    # Vertex AI embedding service
â”‚   â”‚   â”œâ”€â”€ metadata_store.py # Cloud SQL metadata queries
â”‚   â”‚   â””â”€â”€ vector_store.py  # PostgresVectorStore integration
â”‚   â”œâ”€â”€ processing/          # Text chunking and validation
â”‚   â”‚   â”œâ”€â”€ chunker.py       # RecursiveCharacterTextSplitter (paragraph-aware)
â”‚   â”‚   â””â”€â”€ validators.py    # Speech metadata validation
â”‚   â”œâ”€â”€ tools/               # MCP tool implementations
â”‚   â”‚   â”œâ”€â”€ search.py        # Hybrid search with filters
â”‚   â”‚   â””â”€â”€ fetch.py         # Speech retrieval + stats
â”‚   â””â”€â”€ server.py            # FastMCP entrypoint
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ingest_hansard.py    # CLI ingestion (admin operation)
â”‚   â”œâ”€â”€ init_database.py     # Cloud SQL schema initialization
â”‚   â””â”€â”€ setup-cloudsql.sh    # Cloud SQL instance creation
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                # Component tests (models, chunking)
â”‚   â”œâ”€â”€ integration/         # E2E MCP tool tests
â”‚   â””â”€â”€ fixtures/            # Sample speech data
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sk-hansard/          # Simon Kennedy speeches (64 .md files)
â”œâ”€â”€ deployment/              # Cloud Run deployment configs
â””â”€â”€ specs/001-hansard-rag-implementation/
    â”œâ”€â”€ spec.md              # Feature specification
    â”œâ”€â”€ plan.md              # This file
    â”œâ”€â”€ research.md          # Google ADK research
    â”œâ”€â”€ data-model.md        # Database schemas + Pydantic models
    â”œâ”€â”€ quickstart.md        # Local development setup
    â””â”€â”€ contracts/           # MCP tool JSON schemas
```

**Structure Decision**: Single project (Option 1) with FastMCP server. Separation of concerns via:
- **MCP Tools** (`src/tools/`): Read-only query operations exposed to clients
- **CLI Scripts** (`scripts/`): Admin operations for ingestion and setup
- **Storage Layer** (`src/storage/`): LangChain + Cloud SQL integration
- **Processing** (`src/processing/`): Paragraph-aware chunking (800 chars, 150 overlap)

## Complexity Tracking

*Fill ONLY if Constitution Check has violations that must be justified*

No constitution violations requiring justification. Deferred items (OAuth, ChatGPT integration) are intentional MVP scope reductions documented in spec.md.

## Implementation Status

**Phase 0 (Research)**: âœ… COMPLETE
- Google ADK architecture research completed
- LangChain + Vertex AI + Cloud SQL pgvector patterns documented
- Paragraph chunking analysis completed (670 paragraphs, mean 497 chars)

**Phase 1 (Design)**: âœ… COMPLETE
- data-model.md: Dual-table schema (speeches + speech_chunks) with pgvector
- contracts/: MCP tool JSON schemas (search, fetch, dataset_stats)
- quickstart.md: Local development setup with Cloud SQL

**Phase 2 (Implementation)**: ðŸ”„ IN PROGRESS
- âœ… Cloud SQL PostgreSQL instance created (hansard-db)
- âœ… Database schema initialized with pgvector v0.8.0
- âœ… Vector store integration fixed (PostgresEngine, column mapping)
- âœ… 62 speeches ingested into metadata store
- â³ Speech chunks + embeddings ingestion pending (0/62 speeches chunked)
- âœ… MCP server running with 3 tools (search, fetch, dataset_stats)
- â³ End-to-end testing pending (awaiting chunk data)

**Next Steps**:
1. Complete chunk ingestion with Vertex AI embeddings
2. Test search functionality with real data
3. Run integration tests via MCP Inspector
4. Generate fastmcp.json for MCP client distribution

