# Data Model: Australian Hansard RAG

**Branch**: `001-hansard-rag-implementation`
**Date**: 2025-10-22 (Updated)
**Spec**: [spec.md](./spec.md)
**Research**: [research.md](./research.md)

---

## Overview

This document defines the **actual implemented** data model for the Australian Hansard RAG system, using Cloud SQL PostgreSQL with pgvector extension (768-dimensional vectors) per the constitution (v2.6.0) Google ADK-aligned architecture.

**Database**: Cloud SQL PostgreSQL 15 with pgvector v0.8.0
**Vector Dimensions**: 768 (Vertex AI text-embedding-005)
**Schema**: LangChain PostgresVectorStore default (single table)
**Index Type**: HNSW (managed automatically by LangChain)

---

## Database Schema

### Single Table: `langchain_vector_store`

**Implementation Note**: We use **LangChain's default PostgresVectorStore schema** (single table) rather than a custom dual-table design. This provides:
- Built-in compatibility with LangChain's vector store API
- Automatic schema management via `PostgresEngine.ainit_vectorstore_table()`
- Simplified maintenance and updates
- All metadata stored in flexible JSON column
- No foreign key constraints or complex relationships

The table is created and managed by LangChain's `PostgresEngine.ainit_vectorstore_table()` method.

```sql
-- Enable pgvector extension (auto-enabled by LangChain)
CREATE EXTENSION IF NOT EXISTS vector;

-- LangChain default schema
CREATE TABLE langchain_vector_store (
    -- Primary key (LangChain default ID column name)
    langchain_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),

    -- Full speech text (entire speech, not chunked)
    content TEXT NOT NULL,

    -- Vector embedding (768 dimensions from Vertex AI text-embedding-005)
    embedding vector(768) NOT NULL,

    -- All metadata stored as JSON (flexible schema)
    langchain_metadata JSON
);

-- HNSW index for fast vector similarity search
-- Created automatically by LangChain during table initialization
-- Default parameters optimized for 768-dimensional vectors
```

**Table Schema**:

| Column | Type | Description |
|--------|------|-------------|
| `langchain_id` | UUID | Primary key (auto-generated by LangChain, NOT NULL) |
| `content` | TEXT | Full speech text - entire speech stored as single document |
| `embedding` | vector(768) | 768-dimensional vector from Vertex AI text-embedding-005 |
| `langchain_metadata` | JSON | All speech metadata (see Metadata Schema below) |

---

## Metadata Schema

All speech metadata is stored in the `langchain_metadata` JSON column. This provides flexibility and avoids schema migrations.

**Metadata Fields** (stored in `langchain_metadata` JSON):

| Field | Type | Description | Example |
|-------|------|-------------|---------|
| `speech_id` | string | Unique speech identifier from frontmatter | `"2024-house-reps-kennedy-001"` |
| `speaker` | string | MP/Senator name | `"Kennedy, Simon MP"` |
| `speaker_id` | string | Unique speaker identifier | `"10000"` |
| `party` | string | Political party | `"Liberal"` |
| `chamber` | string | Parliamentary chamber | `"House of Reps"` |
| `electorate` | string | Electorate name | `"Cook"` |
| `date` | string | Speech date (ISO 8601) | `"2024-07-01"` |
| `debate` | string | Debate topic | `"Tax Cuts"` |
| `themes` | string | Comma-separated themes | `"cost-of-living,taxation"` |
| `tags` | string | Comma-separated tags | `"economy,budget"` |
| `summary` | string | Brief summary (max 500 chars) | `"Speech supporting tax cuts..."` |

**Validation Rules**:
- All metadata validation occurs in application layer (not database)
- JSON schema is flexible to accommodate different speech types
- No database-level constraints on metadata structure
- Metadata is set during ingestion via `populate_hansard_speeches.py`

---

## Storage Approach: Full Speeches (No Chunking)

**Key Implementation Detail**: Unlike the original spec, the **actual implementation stores entire speeches as single documents** (no chunking).

**Rationale**:
- Simpler implementation for MVP
- Full context preservation
- Easier debugging and maintenance
- LangChain handles embedding generation automatically

**Trade-offs**:
- Larger embeddings (entire speech vs chunks)
- May lose precision for very long speeches
- Search results return full speech (not specific excerpts)

**Future Enhancement**: Chunking can be added later if needed by:
1. Using `RecursiveCharacterTextSplitter` before ingestion
2. Storing chunks with `chunk_index` in metadata
3. Updating search tool to reassemble chunks

---

## Pydantic Models

### SpeechMetadata (Not Currently Used)

The original spec defined Pydantic models for validation, but the **actual implementation** uses simple dictionaries during population:

```python
# Actual implementation (populate_hansard_speeches.py)
metadatas = [
    {
        'speech_id': speech['frontmatter'].get('speech_id', ''),
        'speaker': speech['frontmatter'].get('speaker', ''),
        'speaker_id': speech['frontmatter'].get('speaker_id', ''),
        'date': speech['frontmatter'].get('date', ''),
        'chamber': speech['frontmatter'].get('chamber', ''),
        'electorate': speech['frontmatter'].get('electorate', ''),
        'party': speech['frontmatter'].get('party', ''),
        'debate': speech['frontmatter'].get('debate', ''),
        'themes': ','.join(speech['frontmatter'].get('themes', [])),
        'tags': ','.join(speech['frontmatter'].get('tags', [])),
        'summary': speech['frontmatter'].get('summary', '')[:500],
    }
    for speech in speeches
]
```

**Future Enhancement**: Add Pydantic models for type safety and validation.

---

## Data Flow: Ingestion Pipeline

**Actual Implementation** (`populate_hansard_speeches.py`):

```
Markdown Files (data/sk-hansard/*.md)
   │
   ├─> Parse YAML frontmatter + content
   │   └─> Extract metadata dict
   │
   ├─> Create PostgresEngine (IAM auth)
   │   └─> Connect to Cloud SQL
   │
   ├─> Initialize langchain_vector_store table
   │   └─> ainit_vectorstore_table(vector_size=768)
   │
   ├─> Create VertexAIEmbeddings service
   │   └─> model: text-embedding-005
   │
   ├─> Create PostgresVectorStore
   │   └─> Links engine + embedding service
   │
   └─> Add speeches with embeddings
       └─> store.aadd_texts(texts, metadatas)
           ├─> Generates embeddings automatically
           ├─> Inserts into langchain_vector_store
           └─> Returns list of IDs
```

**Key Points**:
- No duplicate checking (content_hash not implemented)
- No separate speeches table
- No chunking step
- Embeddings generated automatically by LangChain
- All done in single Cloud Run Job

---

## Data Flow: Search Query

**Actual Implementation** (`src/tools/search.py`):

```
User Query (natural language)
   │
   ├─> Get VectorStore instance
   │   └─> Creates PostgresVectorStore with embeddings
   │
   ├─> Generate query embedding (automatic)
   │   ├─> Task type: RETRIEVAL_QUERY
   │   └─> Dimensions: 768
   │
   ├─> Vector similarity search
   │   ├─> asimilarity_search_with_score(query, k=limit)
   │   ├─> HNSW index scan
   │   └─> Returns documents + scores
   │
   ├─> Extract metadata from results
   │   └─> All metadata from langchain_metadata JSON
   │
   └─> Return enriched results
       └─> speech_id, excerpt, speaker, party, etc.
```

**Key Points**:
- No JOIN operations (single table)
- No separate metadata_store
- All metadata from vector search results
- No full-text enrichment step

---

## Database Operations

### Table Creation

```python
# Via populate_hansard_speeches.py or drop_table_job.py
from langchain_google_cloud_sql_pg import PostgresEngine

engine = await PostgresEngine.afrom_instance(
    project_id="skai-fastmcp-cloudrun",
    region="us-central1",
    instance="hansard-db-v2",
    database="hansard"
    # IAM authentication (no user/password)
)

# Create table with correct schema
await engine.ainit_vectorstore_table(
    table_name="langchain_vector_store",
    vector_size=768
)
```

### Table Deletion (Reset)

```python
# Via drop_table_job.py (Cloud Run Job)
DROP TABLE IF EXISTS langchain_vector_store CASCADE;
```

**Important**: Table must be dropped via Cloud Run Job with proper IAM permissions. Local scripts fail due to insufficient privileges.

---

## Current State (as of 2025-10-22)

**Database**: `hansard` on `hansard-db-v2` (Cloud SQL PostgreSQL 15)
**Table**: `langchain_vector_store`
**Rows**: 64 speeches (populated 2025-10-22)
**Schema**: Correct (langchain_id, content, embedding, langchain_metadata)
**Index**: HNSW (created automatically by LangChain)
**Embeddings**: Vertex AI text-embedding-005 (768 dimensions)

**Verification**:
```
✅ Table created with correct schema
✅ 64 speeches populated successfully
✅ Search functionality tested in Cloud Run Job
✅ Sample query: "cost of living and inflation" returns 3 results
```

---

## Troubleshooting

### "Id column, langchain_id, does not exist"

**Cause**: Table was created with incorrect schema (old version or manual creation)
**Solution**:
1. Run `drop-table` Cloud Run Job to drop table
2. Run `populate-hansard` Cloud Run Job to recreate with correct schema
3. Schema must have: `langchain_id` (UUID), `content` (TEXT), `embedding` (vector(768)), `langchain_metadata` (JSON)

### Local testing fails with event loop errors

**Cause**: Cloud SQL Connector event loop incompatibility when running outside GCP
**Solution**: Test via Cloud Run MCP server instead of local scripts
**Note**: This is expected behavior - local testing is not supported for IAM auth

---

## Summary

| Component | Technology | Specification |
|-----------|-----------|---------------|
| **Database** | Cloud SQL PostgreSQL 15 | hansard-db-v2 (db-custom-2-7680) |
| **Vector Extension** | pgvector v0.8.0 | HNSW index (LangChain defaults) |
| **Vector Dimensions** | 768 | Vertex AI text-embedding-005 |
| **Tables** | 1 table | `langchain_vector_store` (LangChain default schema) |
| **Schema** | Single-table | No foreign keys, all metadata in JSON |
| **Chunking** | None | Full speeches stored as single documents |
| **Validation** | Application layer | Dict-based (no Pydantic currently) |
| **Authentication** | IAM | Service account-based (no passwords) |

**Current Scale (64 speeches)**:
- langchain_vector_store: 64 rows
- Total size: ~5 MB (text + embeddings + metadata)
- Expected scale (10,000 speeches): ~800 MB

---

**Data Model Version**: 2.0 (Actual Implementation)
**Alignment**: Constitution v2.6.0 (Google ADK architecture)
**Previous Version**: 1.0 (Dual-table spec - never implemented)
**Next**: See [contracts/](./contracts/) for MCP tool API specifications
